# Database Backup - Production Simple
# Automated PostgreSQL backups with retention policy

# Backup storage PVC
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: backup-storage-pvc
  namespace: carrental-prod
  labels:
    app.kubernetes.io/name: backup-storage-pvc
    app.kubernetes.io/component: backup
    app.kubernetes.io/part-of: carrental-saas
spec:
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 50Gi
  storageClassName: local-storage

---
# Backup ConfigMap with scripts
apiVersion: v1
kind: ConfigMap
metadata:
  name: backup-scripts
  namespace: carrental-prod
  labels:
    app.kubernetes.io/name: backup-scripts
    app.kubernetes.io/component: backup
    app.kubernetes.io/part-of: carrental-saas
data:
  backup.sh: |
    #!/bin/bash
    set -e

    # Configuration
    BACKUP_DIR="/backup"
    RETENTION_DAYS=30
    TIMESTAMP=$(date +%Y%m%d_%H%M%S)
    BACKUP_FILE="carrental_backup_${TIMESTAMP}.sql"

    echo "Starting backup at $(date)"

    # Create backup directory if it doesn't exist
    mkdir -p ${BACKUP_DIR}/daily

    # Create database backup
    echo "Creating database backup..."
    pg_dump -h postgres-service -U ${POSTGRES_USER} -d ${POSTGRES_DB} \
        --verbose --no-password --format=custom \
        --file=${BACKUP_DIR}/daily/${BACKUP_FILE}

    # Compress backup
    echo "Compressing backup..."
    gzip ${BACKUP_DIR}/daily/${BACKUP_FILE}

    # Create a "latest" symlink
    ln -sf ${BACKUP_FILE}.gz ${BACKUP_DIR}/daily/latest.sql.gz

    # Cleanup old backups (keep last 30 days)
    echo "Cleaning up old backups..."
    find ${BACKUP_DIR}/daily -name "carrental_backup_*.sql.gz" -mtime +${RETENTION_DAYS} -delete

    # Log backup completion
    BACKUP_SIZE=$(du -h ${BACKUP_DIR}/daily/${BACKUP_FILE}.gz | cut -f1)
    echo "Backup completed successfully at $(date)"
    echo "Backup file: ${BACKUP_FILE}.gz (${BACKUP_SIZE})"
    echo "Backup stored in: ${BACKUP_DIR}/daily/"

    # Optional: Upload to cloud storage (uncomment and configure as needed)
    # aws s3 cp ${BACKUP_DIR}/daily/${BACKUP_FILE}.gz s3://your-backup-bucket/carrental/
    # gsutil cp ${BACKUP_DIR}/daily/${BACKUP_FILE}.gz gs://your-backup-bucket/carrental/

  restore.sh: |
    #!/bin/bash
    set -e

    if [ -z "$1" ]; then
        echo "Usage: $0 <backup_file>"
        echo "Available backups:"
        ls -la /backup/daily/carrental_backup_*.sql.gz
        exit 1
    fi

    BACKUP_FILE="$1"
    BACKUP_PATH="/backup/daily/${BACKUP_FILE}"

    if [ ! -f "${BACKUP_PATH}" ]; then
        echo "Error: Backup file ${BACKUP_PATH} not found"
        exit 1
    fi

    echo "WARNING: This will restore the database from backup: ${BACKUP_FILE}"
    echo "This operation will overwrite the current database!"
    read -p "Are you sure? (yes/no): " confirm

    if [ "$confirm" != "yes" ]; then
        echo "Restore cancelled."
        exit 1
    fi

    echo "Starting restore at $(date)"

    # Decompress if needed
    if [[ ${BACKUP_FILE} == *.gz ]]; then
        echo "Decompressing backup..."
        gunzip -c ${BACKUP_PATH} > /tmp/restore.sql
        RESTORE_FILE="/tmp/restore.sql"
    else
        RESTORE_FILE=${BACKUP_PATH}
    fi

    # Restore database
    echo "Restoring database..."
    pg_restore -h postgres-service -U ${POSTGRES_USER} -d ${POSTGRES_DB} \
        --verbose --clean --if-exists --no-owner --no-privileges \
        ${RESTORE_FILE}

    # Cleanup temp file
    if [ -f "/tmp/restore.sql" ]; then
        rm /tmp/restore.sql
    fi

    echo "Database restore completed successfully at $(date)"

  health-check.sh: |
    #!/bin/bash
    # Health check for backup system

    BACKUP_DIR="/backup/daily"
    LATEST_BACKUP="${BACKUP_DIR}/latest.sql.gz"

    # Check if latest backup exists
    if [ ! -f "${LATEST_BACKUP}" ]; then
        echo "ERROR: No latest backup found"
        exit 1
    fi

    # Check if backup is recent (less than 25 hours old)
    BACKUP_AGE=$(find ${LATEST_BACKUP} -mtime -1 | wc -l)
    if [ ${BACKUP_AGE} -eq 0 ]; then
        echo "WARNING: Latest backup is older than 24 hours"
        exit 1
    fi

    # Check backup file integrity
    if ! gzip -t ${LATEST_BACKUP} 2>/dev/null; then
        echo "ERROR: Latest backup file is corrupted"
        exit 1
    fi

    echo "Backup system is healthy"
    echo "Latest backup: $(ls -la ${LATEST_BACKUP})"
    exit 0

---
# Daily backup CronJob
apiVersion: batch/v1
kind: CronJob
metadata:
  name: carrental-backup-daily
  namespace: carrental-prod
  labels:
    app.kubernetes.io/name: carrental-backup-daily
    app.kubernetes.io/component: backup
    app.kubernetes.io/part-of: carrental-saas
spec:
  schedule: "0 2 * * *"  # Daily at 2 AM
  timeZone: "UTC"
  successfulJobsHistoryLimit: 7
  failedJobsHistoryLimit: 3
  concurrencyPolicy: Forbid
  startingDeadlineSeconds: 600

  jobTemplate:
    metadata:
      labels:
        app.kubernetes.io/name: carrental-backup-job
        app.kubernetes.io/component: backup
        app.kubernetes.io/part-of: carrental-saas
    spec:
      backoffLimit: 2
      activeDeadlineSeconds: 3600  # 1 hour timeout

      template:
        metadata:
          labels:
            app.kubernetes.io/name: carrental-backup-job
            app.kubernetes.io/component: backup
            app.kubernetes.io/part-of: carrental-saas
        spec:
          restartPolicy: OnFailure

          containers:
          - name: postgres-backup
            image: postgres:15-alpine
            command: ["/bin/bash", "/scripts/backup.sh"]

            env:
            - name: POSTGRES_USER
              valueFrom:
                secretKeyRef:
                  name: carrental-secrets
                  key: SPRING_DATASOURCE_USERNAME
            - name: POSTGRES_DB
              value: "carrental_db"
            - name: PGPASSWORD
              valueFrom:
                secretKeyRef:
                  name: carrental-secrets
                  key: POSTGRES_PASSWORD

            volumeMounts:
            - name: backup-storage
              mountPath: /backup
            - name: backup-scripts
              mountPath: /scripts
              readOnly: true

            resources:
              requests:
                memory: "128Mi"
                cpu: "100m"
              limits:
                memory: "512Mi"
                cpu: "500m"

            securityContext:
              runAsNonRoot: true
              runAsUser: 999
              runAsGroup: 999
              allowPrivilegeEscalation: false
              readOnlyRootFilesystem: true

          volumes:
          - name: backup-storage
            persistentVolumeClaim:
              claimName: backup-storage-pvc
          - name: backup-scripts
            configMap:
              name: backup-scripts
              defaultMode: 0755

          securityContext:
            fsGroup: 999

---
# Weekly backup cleanup job
apiVersion: batch/v1
kind: CronJob
metadata:
  name: carrental-backup-cleanup
  namespace: carrental-prod
  labels:
    app.kubernetes.io/name: carrental-backup-cleanup
    app.kubernetes.io/component: backup
    app.kubernetes.io/part-of: carrental-saas
spec:
  schedule: "0 3 * * 0"  # Weekly on Sunday at 3 AM
  timeZone: "UTC"
  successfulJobsHistoryLimit: 3
  failedJobsHistoryLimit: 1

  jobTemplate:
    spec:
      template:
        spec:
          restartPolicy: OnFailure

          containers:
          - name: backup-cleanup
            image: alpine:latest
            command: ["/bin/sh", "-c"]
            args:
            - |
              echo "Starting backup cleanup..."

              # Keep last 30 daily backups
              find /backup/daily -name "carrental_backup_*.sql.gz" -mtime +30 -delete

              # Create weekly backup from latest daily
              mkdir -p /backup/weekly
              WEEK=$(date +%Y_week_%U)
              if [ -f /backup/daily/latest.sql.gz ]; then
                cp /backup/daily/latest.sql.gz /backup/weekly/carrental_weekly_${WEEK}.sql.gz
              fi

              # Keep last 12 weekly backups (3 months)
              find /backup/weekly -name "carrental_weekly_*.sql.gz" -mtime +84 -delete

              echo "Cleanup completed."
              echo "Disk usage:"
              du -sh /backup/*

            volumeMounts:
            - name: backup-storage
              mountPath: /backup

            resources:
              requests:
                memory: "64Mi"
                cpu: "50m"
              limits:
                memory: "128Mi"
                cpu: "200m"

          volumes:
          - name: backup-storage
            persistentVolumeClaim:
              claimName: backup-storage-pvc

---
# Backup health check service
apiVersion: v1
kind: Service
metadata:
  name: backup-health-service
  namespace: carrental-prod
  labels:
    app.kubernetes.io/name: backup-health-service
    app.kubernetes.io/component: backup
    app.kubernetes.io/part-of: carrental-saas
spec:
  type: ClusterIP
  ports:
  - port: 8080
    targetPort: 8080
    name: http
  selector:
    app.kubernetes.io/name: backup-health-monitor

---
# Backup health monitoring deployment
apiVersion: apps/v1
kind: Deployment
metadata:
  name: backup-health-monitor
  namespace: carrental-prod
  labels:
    app.kubernetes.io/name: backup-health-monitor
    app.kubernetes.io/component: backup
    app.kubernetes.io/part-of: carrental-saas
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: backup-health-monitor
  template:
    metadata:
      labels:
        app.kubernetes.io/name: backup-health-monitor
        app.kubernetes.io/component: backup
        app.kubernetes.io/part-of: carrental-saas
    spec:
      containers:
      - name: health-monitor
        image: nginx:alpine
        ports:
        - containerPort: 8080

        volumeMounts:
        - name: backup-storage
          mountPath: /backup
          readOnly: true
        - name: backup-scripts
          mountPath: /scripts
          readOnly: true
        - name: nginx-config
          mountPath: /etc/nginx/conf.d

        # Health check endpoint
        livenessProbe:
          httpGet:
            path: /health
            port: 8080
          initialDelaySeconds: 10
          periodSeconds: 30

        resources:
          requests:
            memory: "32Mi"
            cpu: "25m"
          limits:
            memory: "64Mi"
            cpu: "100m"

      volumes:
      - name: backup-storage
        persistentVolumeClaim:
          claimName: backup-storage-pvc
      - name: backup-scripts
        configMap:
          name: backup-scripts
      - name: nginx-config
        configMap:
          name: backup-nginx-config

---
# Nginx config for backup health endpoint
apiVersion: v1
kind: ConfigMap
metadata:
  name: backup-nginx-config
  namespace: carrental-prod
  labels:
    app.kubernetes.io/name: backup-nginx-config
    app.kubernetes.io/component: backup
    app.kubernetes.io/part-of: carrental-saas
data:
  default.conf: |
    server {
        listen 8080;

        location /health {
            access_log off;

            # Run health check script and return result
            content_by_lua_block {
                local handle = io.popen("/scripts/health-check.sh 2>&1")
                local result = handle:read("*a")
                local success = handle:close()

                if success then
                    ngx.status = 200
                    ngx.say("OK - Backup system healthy\n" .. result)
                else
                    ngx.status = 500
                    ngx.say("ERROR - Backup system unhealthy\n" .. result)
                end
            }
        }

        location /backup-status {
            alias /backup/;
            autoindex on;
            autoindex_format json;
        }
    }